{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/ulissesdias/tt003/blob/main/notebooks/aula09_policy_improvement.ipynb","timestamp":1698359331548}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"77a04b9f29a14236ba44f877cb61989c":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_4a67b999d9c34effa422dc4ff4fd9c20","IPY_MODEL_2ed5a0852925446892e579dd65f6bc21"],"layout":"IPY_MODEL_5af2e7b9c0b449eeb8d305b0fb63cca1"}},"4a67b999d9c34effa422dc4ff4fd9c20":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"frame","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_dee95d531f4443469113ac7a14c40ea6","max":2,"min":0,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_0a2e8099e301490797101b98be79d37f","value":1}},"2ed5a0852925446892e579dd65f6bc21":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_d8f720d5516c46a6b4dfa084db9b5782","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=200x200>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAELElEQVR4nO3d0W7aWBRAUTqa/wb+fB6iQVEM+NqwbZOu9VQ1YE7Nlp1EoufP5XI5Hc/lcjngYKYa98/eA/A7CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi8S/K55zPp+//nC9XscfM/KsF329xGdNdRvg+xj1VBu8g4uvWN9P04+T8uQxI896xfl8nj3sMaf68v2t2mCq2eO/fq7WXLEOqHsbXjEyVXelfOUVp49ZOudMWHcv1Lv7fVPN3sRXW32rffFWOBPWQd6zH0w17u5Ut7zO5/OjsaePGXnWjZ8K99ddrh693Mj3oz8eM/794pc/Kz459OgiOf0OdPqY09gZXPqRpum/+Xq9ftZUz+d841R3j//2c7UmrA0c87NyphrnVkhCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhAV8Dh+xX8BU49wKSQiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBIrNxXaJfpopFmj/9j8iNMtcOGVbtMx6eaPf7dPVtHmOr02ju4+Ipll+m48V2mW55PG1Yf+qBdpite8Wv13LtSs2F1gQ+aal3Hb7yM2bC6he13mZ6WX4HeeLlaffwdNqzaZbp6qu/XoelpmU4eTXV6/O7YsLoPU437u26FbEZYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSEBXwOH7FfwFTj3ApJCIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICItEsgjTysknr3j3qzfbnKvZqe7OsP8izOnLH2S54/YrJ495rjZYZZoswrRycvwV9zpX9XkIF2FaObn0uVueq9rvWYR5zJWTu9trquqnQisnx218rrbRLsL8y1dOfsS5ej7V6d4JtAjzzUw1zi9ISQiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAgL+Bz+74YFTDXOrZCEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi8Sa1b3HXJI7e/zfuiR39UjpVGtW954m78r0MdsvyR08/vV/20y1wZLcFVPNHn+31b0jj9l+Se6I7yeoXhG4/Xk4jpWre4+5JHdkqtskb78V7rUk97lPWt17zCW5s1Pd/dJtqltq751qdx+zuveYS3JHppr+/UFW9/5Kr67uPeaS3Nmp1v2kc8wluSs+pfPoFa3u3YepxvkFKQlhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFon/AFwB0b9Nas6iAAAAAElFTkSuQmCC\n"},"metadata":{}}]}},"5af2e7b9c0b449eeb8d305b0fb63cca1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dee95d531f4443469113ac7a14c40ea6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a2e8099e301490797101b98be79d37f":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"d8f720d5516c46a6b4dfa084db9b5782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9cba9f898e34ebaa2d2636488cab777":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_60b1233f9150423fad262dcdc585929e","IPY_MODEL_baf16c026e1841d38823888a7fee3658"],"layout":"IPY_MODEL_33813fdbaf6e42acb89ef31d828cd507"}},"60b1233f9150423fad262dcdc585929e":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"frame","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_4f60fecae1844545a7300492fe8fd62d","max":2,"min":0,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_18a52adee9cf445b9b7d31a6cdf3a70c","value":0}},"baf16c026e1841d38823888a7fee3658":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_22cc0ceca56d44d58d3fd80e8411133c","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=400x200>","image/png":"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\n"},"metadata":{}}]}},"33813fdbaf6e42acb89ef31d828cd507":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f60fecae1844545a7300492fe8fd62d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18a52adee9cf445b9b7d31a6cdf3a70c":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"22cc0ceca56d44d58d3fd80e8411133c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869a39bbb3964e64af4edfbddc0b9ccd":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f80d84fd30dd494185e62d9e193e92bd","IPY_MODEL_4c09dbac408340478bf93fbbd0c85880"],"layout":"IPY_MODEL_56a840bfd555416d9e1b5a129950405d"}},"f80d84fd30dd494185e62d9e193e92bd":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"frame","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_e53ed69f4b764211b2ae9d0422a30473","max":2,"min":0,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_c4a431f743e2478998396dea785fb13d","value":1}},"4c09dbac408340478bf93fbbd0c85880":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_9802f2aa3b0845f9bb35276933ee8674","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=200x200>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAENUlEQVR4nO3d0W7aWBRAUTqa/4b8eR/QIBQTfG3Ytsms9RS1YB+ZLQiV3PPncrmcjudyuRxwMFON+2fvAfidhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSEReLfFc85n8/XH76+vsYfM/KsF11P8VlT3Qa4H6Oeavb406kezvnE4nes+8v07WRPHjPyrFecz+fZwx5zqqv712mDqQaPP61nPPQ171gH1L0Mr1j34tVGzvhKUlczYS19A9zG75tq9kN8tZ+mGjnj9DHjc86EdZDX7BtTjXs4VdfxjW+F+9vgZX54uue/Ar7ydnVaEdb97w3376v3I04f8/BZb3Q/wO3nj5hqqp7qNs9Po77FnwPeknY66r1yphrno5CEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICAv4HG6xX8BU43wUkhAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGRWLmv0C7TRSPNHn+6m2jfqfbZsGqX6fhUs8efTn6Eqa423bBql+m48V2mW15PG1Z/9Pt2mX574huXvNmwusAHTbWu4ze+jdmwuoVj7jKdPiv9ZDzohlW7TFfM9tOop0eTH2Gq17n9awFTjft/fRSyGWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAW8DncYr+Aqcb5KCQhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLJIkwrJ5+c8eHf3mxzrWanejjDoqmSRZjT0x9hueMuKyePea1mDzudYelUySJMKyfHz7jXtaqvQ7gI08rJpc/d8lrVfs8izGOunNzdXlNV3wqtnBy38bXaxuKbKaavxPXlPM1t41z0nWLpDQJPvltNv9RMJ99mqtMhr9XzqU6PLuDIVO7SWcBU4/wDKQlhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhAZ/D/92wgKnG+SgkISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiKxZnXvMZfkzh7/ty7JXT1SOtWa1b2nyasyfcz2S3IHj//1n22m2mBJ7oqpZo+/2+rekcdsvyR3xP0FqlcEbn8djmPl6t5jLskdmeo2yds/CvdakvvcJ63uPeaS3NmpHv7Vbapbau+dancfs7r3mEtyR6aa/vlBVvf+Sq+u7j3mktzZqdZ90znmktwVd+n8dEare/dhqnH+gZSEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIvEX+0soBrSSKfxAAAAAElFTkSuQmCC\n"},"metadata":{}}]}},"56a840bfd555416d9e1b5a129950405d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e53ed69f4b764211b2ae9d0422a30473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4a431f743e2478998396dea785fb13d":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"9802f2aa3b0845f9bb35276933ee8674":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"153b0dd9bdd648e4bf7c7f61f2ef38db":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_ef86f9414c7d43b7a9b26a5dcb82d4c5","IPY_MODEL_f4900c3a1d2f4b16a0c0b82d1d1b113c"],"layout":"IPY_MODEL_bed58bc9acf8416a8a215f87f1916526"}},"ef86f9414c7d43b7a9b26a5dcb82d4c5":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"frame","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_606cf2aa11bf4aee8bc9de2c501a3873","max":2,"min":0,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_6479d0f9edee4903bbb3280e7b1553ca","value":1}},"f4900c3a1d2f4b16a0c0b82d1d1b113c":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_aea8507320ff4f0099b368d940b33115","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=400x200>","image/png":"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\n"},"metadata":{}}]}},"bed58bc9acf8416a8a215f87f1916526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"606cf2aa11bf4aee8bc9de2c501a3873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6479d0f9edee4903bbb3280e7b1553ca":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"aea8507320ff4f0099b368d940b33115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b8e387a405544199c63c40d602f33f6":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_bc5d1472a8c24494ba0afbab950eac9b","IPY_MODEL_ca06304377ce494aaefd00f712dfcf64"],"layout":"IPY_MODEL_b049dd5ebbca45f7be3d575f3cde063a"}},"bc5d1472a8c24494ba0afbab950eac9b":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"frame","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_2e8f7b20f9df4fa8860986db121f6eb3","max":19,"min":0,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_e6d0131245804064a8f35e892e92e5da","value":9}},"ca06304377ce494aaefd00f712dfcf64":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_718fc0fbe2dd4513b52037bb3e16cd2f","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=200x200>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAADLklEQVR4nO3c0XKaUBRAUdPJf1/48z44dRxNKAnuGHCtJ4vYkTObC/GBt2maTqwzTZNxrfTn2V+AYxIWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkXh/yP8yxjidTvM8L7x7vcP9lsO7HPLZ4Wf1gBXrZmQfvnseyvn1/ZbXMf/z4btHmtXWsMYY+zqTnmuM8aU+Fir85TaFta9z6DdYXns+e3f5TuN3euSlUGcLVq4997vtsarTxrBu7hh2d/A/ac1Zd3+hvFT11Wvo0z3+54abEVwv7+fX91texGUy13/xLc/qstuPftFHePN86fU8jns9P5CSEBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWsB9v0zQ9+zvsxjRNxrWSSyEJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGReN/4+THG+cU8z+v3WfOpozof+2cHfphZbVqxrmd0Of7/7rPmU0e1fLxHmtWmsOZ53tdp9FxjjNcZ1wPusZbX9nvX59/rDHpf6812W8P6Rh/7Xd63uxzv4Q980837JZFXW36+4eZm/PCzetil8Pqf11vuL3yveSn80IFn5anJX+Cpyev5gZSEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBI/AV4+u5tPhhgkgAAAABJRU5ErkJggg==\n"},"metadata":{}}]}},"b049dd5ebbca45f7be3d575f3cde063a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e8f7b20f9df4fa8860986db121f6eb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6d0131245804064a8f35e892e92e5da":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"718fc0fbe2dd4513b52037bb3e16cd2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99cfe8f394fc4f8c89915c19fb86c576":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_db72b083745f4e52933e46f8d878f0c6","IPY_MODEL_1983c31308714028894abfd18da39aff"],"layout":"IPY_MODEL_214751bed9934c51a84390c05566c717"}},"db72b083745f4e52933e46f8d878f0c6":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"frame","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_c530b9caca5e486080f98501130897bc","max":18,"min":0,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_8513b8573d8143a4b7fa7f1e57761dab","value":9}},"1983c31308714028894abfd18da39aff":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_59033ca38a374d3c80bfb39dc2c8d671","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=200x200>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAEcUlEQVR4nO3dwU7jWBBAUWY0/x3481kgoQgH5/k513HgnBVKO6Ha3I4ByV3/vL+/v53P+/v7CQcz1bh/nz0Av5OwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBI/DfxnMvl8vnBx8fH+DEjz9pj/PU/j7w+bPnIkVOd9lztOVGb37GuX/prvrvHjDxrj/HXX/5pMc/4VOc8V5fL5dsfLR9ZN/OOdUKD/7Ivl8vHx8f1CVo+cvxUBxuZapnd1tDvhPXthU5ypn6aav2Nun6vujlVfVG761lT3QnrJCV9c3Oqwcv/1zm9+cGev+/N5359IXe++LRnTfVLLoVfVa3ktfLGFn3z3v1MsMcxU/0zcefQTz/FLL9Uy2Pexv5KW29pWnnDX3666bAmbrQ64bkamWrkm4T12WbCOsA575Uz1Ti/ICUhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwgJeh1vsNzDVOJdCEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwS1YbV6yPtMt061fXjL3qukg2r3+ZYeeRRXnqX6c1jXv1cbX7Hsst03PRUv+BcTW5YPeEu07tTfX6pro+5fiSaauJS+zv2vs5sWD3nLtO7U10vy/wa4IHXwcfuMn31va+bL4Un32W66fXrXaNzrz/4BnzwVFtN/rrh2z/xB15Q9lifarl2dX0R6343X//uVLW5qbbO6favDUw1zi9ISQiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwgNfhFvsNTDXOpZCEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEhUizCtnNwz1RnO1fWRE9uQkkWYVk7umeoM5+r6yPVHflItwjzYX145udUxq0xnFmEesEZx3QutnHy7d+14ynrOu1Ptea/6NLMI84A1iuteaOXkOddzDn6fdH1mlh+sP31+EebWJ6ZOvnLynOs501Wmm795P2aN4jFTHeNs6zlHptrPXTobmGqcX5CSEBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBbwOvzfDRuYapxLIQlhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiWp179uOxVFz/uyS3GiqneeqWt1bL5eam+rbMb9jSW4x1f5zlazuXX767os3PtXxjlmSe05/enXvYz1rSe7cVDWrex/mWUtyJ6Y6wJ9e3Vs7ZknuOc3cpfPTzwvLHx9WrJ+viTtP7k61cszdeeamWrlkLz/ddFjnPFdu/9rAVOP8gpSEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIvE//UmMDFy+EFyAAAAAElFTkSuQmCC\n"},"metadata":{}}]}},"214751bed9934c51a84390c05566c717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c530b9caca5e486080f98501130897bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8513b8573d8143a4b7fa7f1e57761dab":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"59033ca38a374d3c80bfb39dc2c8d671":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"cells":[{"cell_type":"markdown","source":["**Universidade Estadual de Campinas - Unicamp**\n","\n","**Faculdade de Tecnologia - FT**\n","\n","**Autor:** Ulisses Martins Dias\n","\n","**Disciplina:** TT003 - Tópicos em Computação e Informática III\n","\n","**Aula 09:** Melhorando a Política\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ulissesdias/tt003/blob/main/notebooks/aula09_policy_improvement.ipynb)"],"metadata":{"id":"HK5u7t-CvMDx"}},{"cell_type":"markdown","source":["# Objetivo da Aula\n","\n","Queremos criar um **oráculo**. Entretanto, o nosso oráculo tem uma diferença daqueles feitos nas primeiras aulas desta disciplina. Vamos lembrar do que o nosso antigo oráculo fazia:\n","\n","* O nosso oráculo do início da disciplina era capaz de responder alguma pergunta do tipo:\n","    * Vai chover amanhã?\n","    * Qual o tempo de duração da erupção do geyzer?\n","    * Essa pessoa morreu no naufrágio?\n","\n","Agora o nosso oráculo deve resolver um tipo diferente de pergunta. Ele deve nos ajudar a fazer algum tipo de planejamento, ao invés de responder a alguma pergunta simples. Em outras palavras, pense no cenário:\n","\n","1. Você está preso em um labirinto e possui vários caminhos a seguir.\n","2. Você não sabe exatamente o que fazer e precisa de um oráculo que lhe diga: devo mudar de diração para a esquerda, para a direita ou seguir em frente?\n","\n","Um outro cenário para este novo tipo de oráculo seria:\n","\n","1. Você está jogando um jogo  contra um oponente forte.\n","2. Você quer saber qual a melhor jogada a ser feita. Devo mover meu cavalo para uma casa específica ou capturar um peão com o meu bispo?\n","\n","Note que este oráculo também pretende lhe dar uma resposta correta, mas o cenário onde ele atua é diferente do que estamos habituados."],"metadata":{"id":"1D7fL9V1WBVn"}},{"cell_type":"markdown","source":["# Utilidade do Valor Esperado\n","\n","Até o momento, aprendemos como computar os valor esperado do retorno acumulado descontado quando o agente se move de maneira aleatória por um conjunto de estados. Entretanto, não explicamos ainda para que isso serve. Nesse caso, vamos voltar aos exemplos das aulas anteriores para fornecer uma intuição sobre o motivo de computarmos o valor esperado.\n","\n","## Cenário da Aula Passada\n","\n","A figura a seguir mostra tudo o que precisamos lembrar. A política deve ser entendida como a estratégia seguida pelo agente. No caso deste cenário, o nosso robô jardineiro é muito pouco inteligente e simplesmente se move ao acao.\n","\n","**Política**: vamos considerar uma política que segue a distribuição uniforme de probabilidade. Em outras palavras, em qualquer estado, o agente tem 25% de probabilidade para se mover em qualquer direção.\n","\n","![alt text](http://www.ic.unicamp.br/~udias/si202/grid_world_01.png)\n","\n","Descobrimos depois de alguns cálculos que os valores de estado (ou seja, o valor esperado do custo acumulado ao iniciar em um dado estado e seguindo uma política aleatória) são:"],"metadata":{"id":"eBesv4t_Z-Q8"}},{"cell_type":"markdown","source":["![tt003_aula02asdfasdf.gif](data:image/gif;base64,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)"],"metadata":{"id":"T3fN8yRpw9jH"}},{"cell_type":"markdown","source":["O agente pode então melhorar a política com a seguinte linha de raciocínio. Vamos assumir que o agente está inicialmente no estado $A$ e depois deixamos para você pensar no que aconteceria nos outros estados. O robô jardineiro deve pensar:\n","\n","* Se estou no estado $A$, tenho quatro opções de ações:\n","\n","  1. **Ir para cima.** Nesse caso, tenho um retorno imediato de $0$ e uma promessa de retorno a longo prazo de 4.2 por ter parado novamente no estado $A$ quando o fator de desconto $\\gamma = 0.7$. Nesse caso, o retorno assumido desta ação seria: $r + \\gamma V_{\\pi}(A) = 0 + 0.7 \\times 4.2 = 2.94$\n","\n","  2. **Ir para direita.** Nesse caso, tenho um retorno imediato de $5$ e uma promessa de retorno a longo prazo de 6.0 por ter parado  no estado $B$ quando o fator de desconto $\\gamma = 0.7$. Nesse caso, o retorno assumido desta ação seria: $r + \\gamma V_{\\pi}(A) = 5 + 0.7 \\times 6.0 = 9.20$\n","\n","  3. **Ir para baixo.** Nesse caso, tenho um retorno imediato de $0$ e uma promessa de retorno a longo prazo de 2.2 por ter parado  no estado $C$ quando o fator de desconto $\\gamma = 0.7$. Nesse caso, o retorno assumido desta ação seria: $r + \\gamma V_{\\pi}(A) = 0 + 0.7 \\times 2.2 = 1,54$\n","\n","  4. **Ir para esquerda.** Nesse caso, tenho um retorno imediato de $0$ e uma promessa de retorno a longo prazo de 4.2 por ter parado novamente no estado $A$ quando o fator de desconto $\\gamma = 0.7$. Nesse caso, o retorno assumido desta ação seria: $r + \\gamma V_{\\pi}(A) = 0 + 0.7 \\times 4.2 = 2.94$\n","\n","Baseado nessa linha de raciocínio, o agente deve entender que a escolha mais acertada seria ir para o estado $B$, ao invés de se mover ao acaso, porque isso lhe trará um retorno melhor do qualquer outra ação."],"metadata":{"id":"K1wNGN50w-RZ"}},{"cell_type":"markdown","source":["## Biblioteca Visual\n","\n","Na aula de hoje, iremos entender como ocorre o processo de aprendizado usando o que já conhecemos. Para tanto, iremos utilizar um exemplo um pouco mais complexo, um grid maior que o que vimos em anteriormente.\n","\n","Algumas bibliotecas foram implementadas especificamente para esta disciplina, para imprimir na tela os resultados da computação dos *state values* e da política. Vejamos principalmente como a biblioteca funciona.\n","\n","O primeiro passo será incluir a biblioteca no colab."],"metadata":{"id":"BPoInqtcwENR"}},{"cell_type":"code","source":["## Efetuando o download do código da biblioteca\n","!wget https://www.ic.unicamp.br/~udias/si202/grid_world.py\n","\n","## Importando a biblioteca\n","import grid_world as gw"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wuo_J_IWkg6","outputId":"d558de23-0952-41ed-e771-7743460165f1","executionInfo":{"status":"ok","timestamp":1699569028295,"user_tz":180,"elapsed":2672,"user":{"displayName":"Marcelli Roberta Sarti","userId":"09433722157184530953"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-09 22:30:25--  https://www.ic.unicamp.br/~udias/si202/grid_world.py\n","Resolving www.ic.unicamp.br (www.ic.unicamp.br)... 143.106.7.54, 2801:8a:40c0:cafe::54\n","Connecting to www.ic.unicamp.br (www.ic.unicamp.br)|143.106.7.54|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2668 (2.6K)\n","Saving to: ‘grid_world.py’\n","\n","grid_world.py       100%[===================>]   2.61K  --.-KB/s    in 0s      \n","\n","2023-11-09 22:30:27 (96.7 MB/s) - ‘grid_world.py’ saved [2668/2668]\n","\n"]}]},{"cell_type":"markdown","source":["A biblioteca nos fornece as seguintes funções:\n","\n","1. **draw_policy(policy):** Mostra a política, como uma lista de probabilidades.\n","\n","2. **draw_state_values(state_values):** Mostra os state_values, um valor em cada quadradinho\n","\n","3. **display_sequence(images):** Mostra uma sequência de imagens na tela, sendo\n","que o usuário pode ir para um frame específico\n","\n","Vamos agora aprender a usar cada uma dessas funções assumindo que temos um grid 2x2"],"metadata":{"id":"WGi9NVnZYZNV"}},{"cell_type":"code","source":["##########\n","## draw_policy\n","##########\n","\n","## Aqui vamos colocar as probabilidades de ação\n","## de uma célula genérica\n","policy_cell   = [0.25, 0.25, 0.25, 0.25] # cima, direita, baixo e esquerda.\n","\n","## Aqui vamos colocar a política, ou seja, a\n","## probabilidade de todas as ações em todos os\n","## estadso\n","policy  = [[policy_cell for i in range(2)] for j in range(2)]\n","\n","## Agora vamos colocar a política na tela.\n","gw.draw_policy(policy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"id":"CKDyK6hGZUai","outputId":"ac3485fd-b7ac-4014-e45c-003c7c550c36","executionInfo":{"status":"ok","timestamp":1699569028296,"user_tz":180,"elapsed":57,"user":{"displayName":"Marcelli Roberta Sarti","userId":"09433722157184530953"}}},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=400x200>"],"image/png":"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\n"},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["##########\n","## draw_state_values\n","##########\n","\n","## Vamos colocar um valor de estado parecido com o\n","## que vimos em aulas anteriores.\n","state_values = [[4.17, 6.09],[2.25, 4.17]]\n","\n","## Colocando os state_values na tela\n","gw.draw_state_values(state_values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"id":"XMUE-77AXFdU","outputId":"42a5e23d-d78c-4afe-ecf2-2f5e93502594","executionInfo":{"status":"ok","timestamp":1699569028297,"user_tz":180,"elapsed":54,"user":{"displayName":"Marcelli Roberta Sarti","userId":"09433722157184530953"}}},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=200x200>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAADTklEQVR4nO3cy27iMABAUTrqfyf+81mgQYhn2nDbSThnBcKpEuvaSVnwMc/zgWXmeTZdC/357RNgn4RFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJD5f8lemaTocDmOMJQOOr08eHLUzpwt/OlHnY5Yc9R96wY51Ecr1pzcHbGua1nuwtB6MWXLU/2ntjjVN0xjjwTVfT8q7JXXhTS5/1Y61Zg09vXvu0r39+54t7lVHr7wVbvH6f9g3QhljbHH5rboVXjxgLr/+99yuvmG7E/X6rxsudvvzt1+9EezJ+V51viCvnz7Px9w8ahM+/L70cn6OezlfkJIQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBawHR/zPP/2OWzGPM+mayG3QhLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiLxufL4aZqOL8YYC8ec3j49cJeOl/90urY+V6t2rAdT8HTM+GfNCWzOvVk6fXpzwBZnadWOteSC7415unD3Z5qmMcaDtm4uv584s8ALnrGWJHI95vE+tz9rrnSLi3BtWN+o6g3vgCenvHa/ol7zjHXv4eDmmN3P6U0Xz5TLl9YWt6vD+v8KD1eh3JyIm2Ouh72bi7k6n6WN9nTiV5O/wK8mL+cLUhLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiLxF/sB7+rQtHcFAAAAAElFTkSuQmCC\n"},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["##########\n","## diplay_sequence\n","##########\n","\n","## Vamos colocar na tela uma sequência de frames.\n","## Usaremos como exemplo a convergência do\n","## bootstrapping vista em aulas anteriores\n","\n","bootstrapping = [\n","    [[0.00 , 0.00] , [0.00 , 0.00]],\n","    [[1.25 , 2.50] , [0.00 , 1.25]],\n","    [[2.12 , 3.81] , [0.44 , 2.12]],\n","    [[2.74 , 4.58] , [0.90 , 2.74]],\n","    [[3.17 , 5.06] , [1.27 , 3.17]],\n","    [[3.47 , 5.38] , [1.55 , 3.47]],\n","    [[3.68 , 5.60] , [1.76 , 3.68]],\n","    [[3.82 , 5.75] , [1.90 , 3.82]],\n","    [[3.93 , 5.85] , [2.00 , 3.93]],\n","    [[4.00 , 5.92] , [2.08 , 4.00]],\n","    [[4.05 , 5.97] , [2.13 , 4.05]],\n","    [[4.08 , 6.01] , [2.16 , 4.08]],\n","    [[4.11 , 6.03] , [2.19 , 4.11]],\n","    [[4.13 , 6.05] , [2.20 , 4.13]],\n","    [[4.14 , 6.06] , [2.22 , 4.14]],\n","    [[4.15 , 6.07] , [2.22 , 4.15]],\n","    [[4.15 , 6.08] , [2.23 , 4.15]],\n","    [[4.16 , 6.08] , [2.23 , 4.16]],\n","    [[4.16 , 6.08] , [2.24 , 4.16]],\n","    [[4.16 , 6.08] , [2.24 , 4.16]]\n","]\n","images = []\n","for value in bootstrapping :\n","  images.append(gw.draw_state_values(value))\n","gw.display_sequence(images)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267,"referenced_widgets":["8b8e387a405544199c63c40d602f33f6","bc5d1472a8c24494ba0afbab950eac9b","ca06304377ce494aaefd00f712dfcf64","b049dd5ebbca45f7be3d575f3cde063a","2e8f7b20f9df4fa8860986db121f6eb3","e6d0131245804064a8f35e892e92e5da","718fc0fbe2dd4513b52037bb3e16cd2f"]},"id":"udIBAKZXamn5","outputId":"312ff3ff-09f6-49d8-c964-aaebfbddce1b","executionInfo":{"status":"ok","timestamp":1699569028298,"user_tz":180,"elapsed":53,"user":{"displayName":"Marcelli Roberta Sarti","userId":"09433722157184530953"}}},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=9, description='frame', max=19), Output()), _dom_classes=('widget-intera…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b8e387a405544199c63c40d602f33f6"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<function grid_world.display_sequence.<locals>._show(frame=(0, 19))>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"4qloZwCPuCmj"},"source":["# Novo Cenário\n","\n","Vamos ver como a escolha da melhor política funciona em um exemplo um pouco maior que o das aulas anteriores.\n","\n","Considere o grid quatro por quatro mostrado aqui. Os estados terminais são localizados nos cantos superior esquerdo e inferior direito.\n","![alt text](http://www.ic.unicamp.br/~udias/si202/grid_world_02.png)\n","\n","Em outras palavras, assuma que este grid representa uma caixa onde será colocado um ratinho. O objetivo do ratinho é fugir desta caixa no menor intervalo de tempo possível, mas ele não sabe onde é a saída. A cada segundo, o ratinho  se moverá de uma célula para outra até chegar em uma das saídas (localizadas nos cantos superior esquerdo e inferior direito).\n","\n","Se uma ação mover o agente para fora da grade, ele será mantido no mesmo estado, o que representa o fato de o ratinho ter batido na parede.\n","\n","\n","## Recompensa\n","\n","Como o objetivo do ratinho é fugir da caixa, devemos recompensar mais quando ele conseguir fugir mais rápido. Isso também pode ser visto de outra forma, podemos penalizar mais os ratinhos que demorarem muito para sair. Esta segunda forma de pensar leva a uma estratégia mais rápida de resolução do problema.\n","\n","A cada movimento do ratinho de uma célula para outra, ele receberá uma penalidade, que aqui representaremos como a atribuição do valor $-1$. Você pode imaginar esse valor $-1$ como um choque que o ratinho leva (nada muito agressivo, um choque leve).\n","\n","O ratinho quer sair da caixa levando o mínimo de choques possível. Isso quer dizer que ele quer receber o mínimo de recompensa $-1$.  \n","\n","## Política\n","\n","Vamos começar com uma política de distribuição aleatória uniforme. Em outras palavras, em cada célula o ratinho pode escolher uma das quatro células ao redor para se mover com uma probablidade de $\\frac{1}{4}$.\n"]},{"cell_type":"code","metadata":{"id":"3lbBsTStuNA7","executionInfo":{"status":"ok","timestamp":1699569028298,"user_tz":180,"elapsed":48,"user":{"displayName":"Marcelli Roberta Sarti","userId":"09433722157184530953"}}},"source":["## Em cada célula o ratinho tem uma recompensa\n","## negativa de -1, ou seja, está levando um\n","## choque leve.\n","rewards = [\n","    [-1, -1, -1, -1],\n","    [-1, -1, -1, -1],\n","    [-1, -1, -1, -1],\n","    [-1, -1, -1, -1]\n","]\n","\n","## O ratinho vai se mover ao acaso pela caixa,\n","## ou seja, terá uma probabilidade de 0.25 para se\n","## mover para cima, direita, baixo e esquerda. Usaremos\n","## essa ordem como canônica.\n","policy_cell   = [0.25, 0.25, 0.25, 0.25] # cima, direita, baixo e esquerda.\n","policy_array  = [[policy_cell for i in range(4)] for j in range(4)]\n","\n","## Os estados finais são os cantos superior esquerdo\n","## e inferior direito. Para garantir que o ratinho\n","## ficará preso nesses estados, faremos com que a\n","## probabilidade de sair desse estado seja $0$ para\n","## qualquer uma das direções.\n","policy_array[0][0] = [0.00, 0.00, 0.00, 0.00]\n","policy_array[3][3] = [0.00, 0.00, 0.00, 0.00]\n","\n","\n","## Para computar o valor esperado descontado de cada\n","## um dos estados, precisamos de fator de desconto\n","## gamma que atribuireoms o valor 0.7. Você pode\n","## definir um gamma no intervalo (0,1).\n","gamma   = .7\n","\n","## Abaixo, todos os movimentos a partir de um\n","## determinado estado. O estado é dado pelas\n","## coordenadas i,j de uma célula no gridworld.\n","## Escreva as funções assumindo que o grid\n","## possui paredes laterais.\n","def move_up(state) :\n","  a, b = state\n","  a -= 1\n","  if a < 0:\n","    a = 0\n","  return (a,b)\n","\n","def move_right(state) :\n","  a, b = state\n","  b += 1\n","  if b > 3:\n","    b = 3\n","  return (a,b)\n","\n","def move_down(state) :\n","  a, b = state\n","  a += 1\n","  if a > 3:\n","    a = 3\n","  return (a,b)\n","\n","def move_left(state) :\n","  a, b = state\n","  b -= 1\n","  if b < 0:\n","    b = 0\n","  return (a,b)\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Valor de Estado\n","\n","Conhecido o problema, devemos saber computar o valor esperado do ganho acumulado de cada um dos estados, como fizemos em aulas anteriores. O modo como faremos isso não difere do que fizemos em aulas anteriores.\n","\n","Sejam:\n","\n","* $cel$: uma célula genérica que queremos computar o valor. Chamaremos esta célula de estado atual.\n","* $up$: o estado acima do estado atual.\n","* $rg$: o estado à direita do estado atual.\n","* $dw$: o estado abaixo do estado atual.\n","* $lf$: o estado à esquerda do estado atual.\n","* $\\pi(s, a)$: uma política que engloba a probabilidade de todas as ações a partir de cada um  dos estados.\n","* $r$: uma recompensa imediata recebida pelo agente ao se mover para um estado vizinho.\n","* $gamma$: um fator de desconto para recompensas futuras.\n","\n","Note que $up$, $rg$, $dw$ e $lf$ podem ser o próprio estado se o agente bater na parede, sem perda de generalidade.\n","\n","A fórmula para computar o valor de estado $V_{\\pi}(cel)$ do estado representado pela célula $cel$ usando bootstrapping será dada por:\n","\\begin{align}\n","V_{\\pi}(cel) = & \\pi(cel, up)  (r(up) + \\gamma V_{\\pi}(up)) + \\\\\n","& \\pi(cel, rg)  (r(rg) + \\gamma  V_{\\pi}(rg)) +\\\\\n","& \\pi(cel, dw)  (r(dw) + \\gamma  V_{\\pi}(dw)) +\\\\\n","& \\pi(cel, lf)  (r(lf) + \\gamma  V_{\\pi}(lf))\\\\\n","\\end{align}\n","\n","Novamente, temos uma grande fórmula recursiva que precisamos iterar até convergir. A técnica de programação dinâmica será muito útil aqui, dado que a recursão será traduzida por chamadas iterativas com o suporte de uma tabela. Vejamos uma implementação a seguir."],"metadata":{"id":"1R1l-zx2iK8s"}},{"cell_type":"code","source":["## Vamos primeiro criar uma função que retorna todos os state_values a partir\n","## de uma política. Note que quardaremos os valores parciais de estado nas\n","## variáveis \"current_values\" e \"next_values\". Note também que também computaremos\n","## um delta que representará o quanto \"current_values\" e \"next_values\" diferem.\n","\n","## O retorno da função será uma matriz contendo o resultado final dos valores\n","## de estado após a convergência e a sequência de valores para podermos\n","## plotar na tela.\n","def find_state_values(rewards, policy_array, gamma, steps = 10000) :\n","  current_values = [\n","      [ 0, 0, 0, 0],\n","      [ 0, 0, 0, 0],\n","      [ 0, 0, 0, 0],\n","      [ 0, 0, 0, 0]\n","  ]\n","\n","  all_values = []\n","\n","  for step in range(steps) :\n","\n","    next_values = [\n","        [ 0, 0, 0, 0],\n","        [ 0, 0, 0, 0],\n","        [ 0, 0, 0, 0],\n","        [ 0, 0, 0, 0]\n","    ]\n","\n","    ## A variável a seguir auxilia na condição de parada\n","    delta = 0\n","\n","    ## Colocaremos o est.\n","    for i in range(4) :\n","      for j in range(4) :\n","        state = (i,j)\n","\n","        up = move_up(state)\n","        rg = move_right(state)\n","        dw = move_down(state)\n","        lf = move_left(state)\n","\n","        policy = policy_array[i][j]\n","\n","        ## ToDo: atualize o valor usando bootstrapping.\n","        next_values[i][j] = (\n","            policy[0]*(rewards[up[0]][up[1]] + gamma  * current_values[up[0]][up[1]]) +\n","            policy[1]*(rewards[rg[0]][rg[1]] + gamma  * current_values[rg[0]][rg[1]]) +\n","            policy[2]*(rewards[dw[0]][dw[1]] + gamma  * current_values[dw[0]][dw[1]]) +\n","            policy[3]*(rewards[lf[0]][lf[1]] + gamma  * current_values[lf[0]][lf[1]])\n","        )\n","\n","        ## Criamos um delta para ajudar na condição de parada.\n","        delta = max(delta, abs(next_values[i][j] - current_values[i][j]))\n","\n","    all_values.append(current_values)\n","\n","    current_values = next_values\n","\n","    ## Para que não fique iterando muito, vamos adicionar um delta.\n","    if (delta < .001) :\n","      return current_values, all_values\n","\n","  return current_values, all_values\n","\n","state_values, all_values = find_state_values(rewards, policy_array, gamma)\n","for line in state_values :\n","  print(line)\n","\n","images = []\n","for value in all_values :\n","  images.append(gw.draw_state_values(value))\n","gw.display_sequence(images)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340,"referenced_widgets":["99cfe8f394fc4f8c89915c19fb86c576","db72b083745f4e52933e46f8d878f0c6","1983c31308714028894abfd18da39aff","214751bed9934c51a84390c05566c717","c530b9caca5e486080f98501130897bc","8513b8573d8143a4b7fa7f1e57761dab","59033ca38a374d3c80bfb39dc2c8d671"]},"id":"-qxhsTVUiNh6","outputId":"7601d0af-a239-4956-80a2-55b0424b3de9","executionInfo":{"status":"ok","timestamp":1699569028299,"user_tz":180,"elapsed":48,"user":{"displayName":"Marcelli Roberta Sarti","userId":"09433722157184530953"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.0, -2.4931726290734955, -3.0788167126249313, -3.195542439209486]\n","[-2.4931726290734955, -2.9620909860403764, -3.113888762076363, -3.0788167126249313]\n","[-3.0788167126249313, -3.1138887620763622, -2.9620909860403764, -2.4931726290734955]\n","[-3.1955424392094858, -3.078816712624931, -2.4931726290734955, -0.0]\n"]},{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=9, description='frame', max=18), Output()), _dom_classes=('widget-intera…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99cfe8f394fc4f8c89915c19fb86c576"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<function grid_world.display_sequence.<locals>._show(frame=(0, 18))>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"T-qa3sSfS8yw"},"source":["# Gerando Novas Políticas\n","\n","Agora que temos os **state-values** para a  política de distribuição uniforme, podemos obter uma nova política, melhor que a anterior, ao escolher o que chamamos de **greedy-action**.\n","\n","Em outras palavras, se estamos em um dado estado, podemos escolher dentre todas as ações disponíveis aquela que nos leva a um estado $s'$ com um valor de $r + \\gamma V_{\\pi}(s')$ maior.\n","\n","Essa nova política será melhor que a anterior, a não ser que a política anterior já seja ótima (ou uma das ótimas). Esse conceito possui diversas ramificações e uma base formal bastante sólida que não detalharemos nesta aula.\n","\n","A seguir, criamos um algoritmo que, a partir dos estados, obtém uma política melhor que a anterior."]},{"cell_type":"code","metadata":{"id":"oSsGd0lkS-jj","colab":{"base_uri":"https://localhost:8080/","height":435},"outputId":"1005ccb4-4f8c-4b21-ce72-d81b39aa5365"},"source":["def find_greedy_policy(state_values, rewards, gamma) :\n","  policy_array  = [[ [0,0,0,0] for i in range(4)] for j in range(4)]\n","\n","  for i in range(4) :\n","    for j in range(4) :\n","\n","      ## Inicialmente, vamos descartar os estados finais.\n","      if (i == j == 0) :\n","          continue\n","      if (i == j == 3) :\n","          continue\n","\n","      state = (i,j)\n","\n","      up = move_up(state)\n","      rg = move_right(state)\n","      dw = move_down(state)\n","      lf = move_left(state)\n","\n","      best_state = max( (\n","          rewards[up[0]][up[1]] + gamma*state_values[up[0]][up[1]],\n","          rewards[rg[0]][rg[1]] + gamma*state_values[rg[0]][rg[1]],\n","          rewards[dw[0]][dw[1]] + gamma*state_values[dw[0]][dw[1]],\n","          rewards[lf[0]][lf[1]] + gamma*state_values[lf[0]][lf[1]]\n","        )\n","      )\n","\n","      ## Criando um array para facilitar o algoritmo\n","      neighbors = [ up, rg, dw, lf ]\n","\n","      ## Computando o número de empates para criar uma política estocástica\n","      ties = 0\n","      for neighbor in neighbors :\n","        if rewards[neighbor[0]][neighbor[1]] + gamma*state_values[neighbor[0]][neighbor[1]] == best_state :\n","          ties += 1\n","      prob = 1.0/ties\n","\n","      ## Verificando quem possui valor igual ao melhor\n","      for k in range(4) :\n","        neighbor  = neighbors[k]\n","        if rewards[neighbor[0]][neighbor[1]] + gamma*state_values[neighbor[0]][neighbor[1]] == best_state :\n","          policy_array[i][j][k] = 1.0/ties\n","  return policy_array\n","\n","policy = find_greedy_policy(state_values, rewards, gamma)\n","\n","display(gw.draw_state_values(state_values))\n","print(\"------------------------\")\n","display(gw.draw_policy(policy))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=200x200>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAEgklEQVR4nO3d0W7aWBRAUTqa/4b8eR+QEEoIXNtsc6FrPc10bHLG7Jg2knv+nE6nw3xOp9OEg5lq3H+vHoDPJCwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBL/rzjneDye/+Hr62v8mJGzthh//fOR58NmmGrOa7VxqsV3rJvvysNjRs7aYvz1r//rDFPNea22T7XmjjWhwe/s4/H49fVVvFs3RfebjUam2j75g7C+vQeTXKnfprr+rnp41vnI4/H4rM5uTrXiQ+16qu0XfMtUW2Z4ENYkJX1zc6rBq3C5pue71xM/cW5+6cvrn7/cyOtc/kcWnfX0qTaW/SEfhddvxuHu1Rw8+LlTRa+/zshU2y/R4t+8X3+LX79V19/0P4+5edbTfbvxPPyYq6ea81qNTHX5xftn3fFnwkfSDrM+K2eqcX5ASkJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSEBbwPj9gvYKpxPgpJCIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEhUG1avj7TL9OHr/9xRk+4detcNq9/mWHTWOm+9y3Tpbql9pjpsu1aL71gfucs0ujGM7zL9bc/Wq6babuWG1Ql3mT6c6rcZZthl2nnV3tc1G1bn3GU6MtXNGV6+yzT1qr2viz8KJ99leucL7b/v9H03rG63+CmdO7fWn7Ou/lPh0idPBqfa+CedFc/D/PYVfw5wx/3ZiqnuHPNwnjOPfy1gqnF+QEpCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhAW8D4/YL2CqcT4KSQiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLRLUI08rJ8ammvVaHDUtrkkWYVk4umuow37W6PnLpWWfVIsydfeTKyReu5zxsXmW6ZhHmDmsU95nqud5oPefD19++ynTNIswd1ijuM9VzvdF6zsFqLyMdl68yXb8Ic+mJqcmnmnM9Z7rKdM3DFDusUfyMlZNzrufcZ5Wpp3QWMNU4PyAlISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISzgffi7GxYw1TgfhSSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJP6t1b1zTnV95D67F3e4Vv/W6t4Jp7o+culZ3VTbr1Wyunf/vYGzbSo822dJ7pzC1b3disc3Wih8eHQdti/JXTdVrVrdmy4OfaOFwjssyV0x1Q6S1b2r972u9r6re7cvyZ3T4t+839z0evPWff0r9/fDbjcy1c9j6qkuY3z71/u3os+4Vh7/WsBU4/yAlISwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi8Rf2MN7c+uEcmwAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=400x200>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"uEeP_NJ9hjIu"},"source":["# Algoritmo Para Melhorar a Política\n","\n","Um algoritmo que iterativamente encontra melhores políticas pode ser construído da seguinte forma:\n","\n","\n","\n","1.   Primeiramente, escolhemos uma política ao acaso.\n","2.   Feito isso, computamos todos os state-values. Chamaremos esse passo de **Evaluation**.\n","3.   Esses state-values nos permitem gerar uma greedy-policy. Chamaremos esse passo de  **Improvement**.\n","4.   Feito isso, computamos todos os state-values novamente. Esse passo, continuaremos chamando de **Evaluation**.\n","5.   Esses state-values nos permitem gerar uma greedy-policy de novo. Esse passo será novamente chamado de  **Improvement**.\n","6.   Continuaremos fazendo isso até não ser mais possível melhorar a nossa política.\n","\n","\n","## Novo Cenário\n","No exemplo anterior, usamos um cenário em que a política ótima é alcançada em apenas uma iteração.\n","Vamos criar alguns obstáculos em algumas células do grid para que a política ótima seja obtida em um número maior de passos. Em outras palavras, vamos eleger três células que darão no ratinho um choque maior.\n","\n","As células (2,3), (3,3) e (4,3), quando alcançadas, fornecem uma penalidade de -100.\n"]},{"cell_type":"code","metadata":{"id":"hWxGIww4hlfi","colab":{"base_uri":"https://localhost:8080/","height":517,"referenced_widgets":["77a04b9f29a14236ba44f877cb61989c","4a67b999d9c34effa422dc4ff4fd9c20","2ed5a0852925446892e579dd65f6bc21","5af2e7b9c0b449eeb8d305b0fb63cca1","dee95d531f4443469113ac7a14c40ea6","0a2e8099e301490797101b98be79d37f","d8f720d5516c46a6b4dfa084db9b5782","a9cba9f898e34ebaa2d2636488cab777","60b1233f9150423fad262dcdc585929e","baf16c026e1841d38823888a7fee3658","33813fdbaf6e42acb89ef31d828cd507","4f60fecae1844545a7300492fe8fd62d","18a52adee9cf445b9b7d31a6cdf3a70c","22cc0ceca56d44d58d3fd80e8411133c"]},"outputId":"f2e39403-7ffc-4e03-f9ed-b0a47893f401"},"source":["## Resumo inicial\n","def find_optimal_policy(rewards, gamma, evaluation_steps = 10000) :\n","    policy_cell = [0.25, 0.25, 0.25, 0.25] # Primeira política\n","    policy     = [[policy_cell for i in range(4)] for j in range(4)]\n","    policy[0][0] = [0.00, 0.00, 0.00, 0.00]\n","    policy[3][3] = [0.00, 0.00, 0.00, 0.00]\n","\n","    ## Vamos guardar todas as políticas neste array.\n","    all_policies = []\n","\n","    ## Vamos guardar todos os state-values neste array.\n","    all_states   = []\n","\n","    while True :\n","       state_values, all_values = find_state_values(rewards, policy, gamma, steps = evaluation_steps)\n","       new_policy      = find_greedy_policy(state_values, rewards, gamma)\n","\n","       if policy == new_policy :\n","          return policy, all_policies, all_states\n","\n","       all_policies.append(policy)\n","       all_states.append(state_values)\n","\n","       policy = new_policy\n","\n","####\n","rewards = [\n","    [-1, -1, -1, -1],\n","    [-1, -1, -100, -1],\n","    [-1, -1, -100, -1],\n","    [-1, -1, -100, -1]\n","]\n","gamma = 0.7\n","optimal, all_policies, all_states = find_optimal_policy(rewards, gamma)\n","\n","images = []\n","for value in all_states :\n","  images.append(gw.draw_state_values(value))\n","gw.display_sequence(images)\n","\n","print(\"-------\")\n","\n","images = []\n","for value in all_policies :\n","  images.append(gw.draw_policy(value))\n","gw.display_sequence(images)\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=1, description='frame', max=2), Output()), _dom_classes=('widget-interac…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a04b9f29a14236ba44f877cb61989c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["-------\n"]},{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=1, description='frame', max=2), Output()), _dom_classes=('widget-interac…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9cba9f898e34ebaa2d2636488cab777"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<function grid_world.display_sequence.<locals>._show(frame=(0, 2))>"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["Note que neste novo cenário foram necessárias três iterações da política para convergirmos para uma situação ótima. Vamos explicar os três quadros:\n","\n","* **Quadro 0:** este quadro é o inicial, criado seguindo a ideia de que em cada estado as ações são equiprováveis.\n","\n","* **Quadro 1:** este quadro foi criado a partir dos valores de estado do Quadro 0. Note que várias células já possuem uma estratégia ótima. Por exemplo:\n","\n","    * as células próximas do canto superior esquerdo já seguem nessa direção para permitir a saída do agente com o número mínimo de passos.\n","    * As células adjacentes às marcadas com -100 de recompensa já entenderam que é importante evitar o caminho que cruza as grandes penalidades.\n","\n"," Entretanto, a célula que está no canto superior direito é bastante problemática (chamaremos, por isso, esta célula de \"célula problemática\"). Note que o agente jamais conseguirá sair dessa célula, dado que a política pede para o agente bater na parede de cima ou na parede da direita. Precisamos entender o motivo de isso o ocorrer.\n","\n","    * Do lado esquerdo da célula problemática, existe uma posição  adjacente a uma célula -100 (ela está acima do -100). Nesse caso, como no Quadro 0 a probabilidade de cair no -100 era de $\\frac{1}{4}$, o agente entende que esta célula é muito arriscada, evitando chegar nela.\n","\n","    * Abaixo da célula problemática, existe outra posição  adjacente a uma célula -100 (ela está do lado diretio da célula -100). Nesse caso, como no Quadro 0 a probabilidade de cair no -100 era de $\\frac{1}{4}$, o agente entende que esta célula é muito arriscada, evitando chegar nela.\n","\n"," Assim, a célula problemática está evitando ir para a esquerda e ir para baixo, o que a força a bater na parede de cima e na parede do lado direito.\n","\n"," * Quadro 2: este quadro já possui uma política ótima. Neste caso, o agente (ratinho) pode usar essa política como um oráculo e, a cada instante, usar este oráculo para sair da caixa no menor tempo possível."],"metadata":{"id":"c1zLgkbvRb5-"}},{"cell_type":"markdown","metadata":{"id":"nf93oWDs4C8_"},"source":["## Diminuindo o Número de Iterações\n","\n","Até o momento, temos usado o algoritmo que itera entre **evaluation** e **improvement** de uma maneira rígida:\n","\n","1. Executamos **evaluation** até a convergência.\n","2. Executamos o **improvement**.\n","\n","Entretanto, podemos encontrar as políticas ótimas com um número muito menor de passos se não tentarmos convergir o **evaluation**.\n","\n","Em outras palavras, podemos usar um número menor de iterações em **evaluation** para nos aproximarmos da direção correta, sempre fazendo progressos, mas sem a preocupação em concluir a obtenção dos valores de estado. Fazendo isso, podemos diminuir o tempo computacional necessário.\n","\n","A seguir, vamos repetir o passo de encontrar as políticas ótimas. Entretanto, vamos executar apenas 5 passos do algoritmo de evaluation."]},{"cell_type":"code","metadata":{"id":"ZZ_8hLh06uXA","colab":{"base_uri":"https://localhost:8080/","height":517,"referenced_widgets":["869a39bbb3964e64af4edfbddc0b9ccd","f80d84fd30dd494185e62d9e193e92bd","4c09dbac408340478bf93fbbd0c85880","56a840bfd555416d9e1b5a129950405d","e53ed69f4b764211b2ae9d0422a30473","c4a431f743e2478998396dea785fb13d","9802f2aa3b0845f9bb35276933ee8674","153b0dd9bdd648e4bf7c7f61f2ef38db","ef86f9414c7d43b7a9b26a5dcb82d4c5","f4900c3a1d2f4b16a0c0b82d1d1b113c","bed58bc9acf8416a8a215f87f1916526","606cf2aa11bf4aee8bc9de2c501a3873","6479d0f9edee4903bbb3280e7b1553ca","aea8507320ff4f0099b368d940b33115"]},"outputId":"9a9bc4ce-50b1-4721-aeb2-fddaf659f45d"},"source":["rewards = [\n","    [-1, -1, -1, -1],\n","    [-1, -1, -100, -1],\n","    [-1, -1, -100, -1],\n","    [-1, -1, -100, -1]\n","]\n","gamma = 0.7\n","optimal, all_policies, all_states = find_optimal_policy(rewards, gamma,evaluation_steps=5)\n","\n","images = []\n","for value in all_states :\n","  images.append(gw.draw_state_values(value))\n","gw.display_sequence(images)\n","\n","print(\"-------\")\n","\n","images = []\n","for value in all_policies :\n","  images.append(gw.draw_policy(value))\n","gw.display_sequence(images)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=1, description='frame', max=2), Output()), _dom_classes=('widget-interac…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"869a39bbb3964e64af4edfbddc0b9ccd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["-------\n"]},{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=1, description='frame', max=2), Output()), _dom_classes=('widget-interac…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"153b0dd9bdd648e4bf7c7f61f2ef38db"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<function grid_world.display_sequence.<locals>._show(frame=(0, 2))>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"dhsCxGTg33eS"},"source":["## Exercício\n","\n","Além da diminuição do número de passos em **evaluation**, podemos desejar que as iterações não ocorram de maneira ordenada como temos feito até agora. Podemos, por exemplo, escolher uma célula ao acaso e atualizar o valor daquela célula baseando-nos nos valores das células ao redor. Isso também irá convergir se todos os estados forem visitados. A vantagem dessa estratégia será, por exemplo, alterar mais vezes uma região próxima daquelas que tiveram seus pesos alterados, o que traria algum ganho computacional. Implemente essa estratégia em um algoritmo de **evaluation** e analise o desempenho.\n"]}]}